{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGeneration-LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetansolanke14/NaturalLanguageProcessing/blob/master/DeepLearningWithNLP/TextGeneration_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWLDvKj0nWur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1 Process Text\n",
        "#2 CleanText\n",
        "#3 Tokenize Text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du3WQl3wqsTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(filepath):\n",
        "  with open(filepath) as f:\n",
        "    str_text =f.read()\n",
        "    \n",
        "  return str_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "873vZd9nq3ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read_moby dick four chapter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFdsvx9Cq6oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhYicPw9q7qA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp =spacy.load('en',disable=['parser','tagger','ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gNBdBqOrDEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp.max_length= 1198623 #totalword in moby ick book"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27MGsE24rQ5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saperate_punc(doc_text):\n",
        "  return[token.text.lower() for token in nlp(doc_text) \n",
        "        if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dz-dciJr8w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d =read_file('moby_dick_four_chapters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrlWXDVFsIny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens =saperate_punc(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbhQEsf4sMtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "105d4450-25d5-4f39-b49f-58f067ba669e"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDFa0h3msN2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pass 25 words and have network to predict word number 26"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nahq9SJlsZQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_len=25+1\n",
        "\n",
        "text_sqequences=[]\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "  seq =tokens[i-train_len:i]\n",
        "  \n",
        "  text_sqequences.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DNo0yQPs4oB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f91bd465-da33-4661-ef59-936c44175a4b"
      },
      "source": [
        "type(text_sqequences)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elc0_MN2s6T0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dc271bf-cf71-4b1a-ddfa-d62215d5ba98"
      },
      "source": [
        "' '.join(text_sqequences[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAvzsBQrs9fU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbc0966c-8cb7-4a69-b36d-a814d8318d8a"
      },
      "source": [
        "' '.join(text_sqequences[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1hcn3WhtJQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7b0cb21-ee65-468c-d606-4303c43a9cc9"
      },
      "source": [
        "' '.join(text_sqequences[2])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGIOINKOtMtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "434c9412-9869-43b4-af99-6630a56dbf33"
      },
      "source": [
        "' '.join(text_sqequences[3])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gqimrQitPOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1402a916-515c-415b-ee7d-817dec280741"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-cJhNfgtUoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer =Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb22RkqvtWw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(text_sqequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlTWNATtjjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences =tokenizer.texts_to_sequences(text_sqequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f658oAGqtnTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "356d44e4-7192-4c28-9119-4086f15c83e9"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[956,\n",
              " 14,\n",
              " 263,\n",
              " 51,\n",
              " 261,\n",
              " 408,\n",
              " 87,\n",
              " 219,\n",
              " 129,\n",
              " 111,\n",
              " 954,\n",
              " 260,\n",
              " 50,\n",
              " 43,\n",
              " 38,\n",
              " 315,\n",
              " 7,\n",
              " 23,\n",
              " 546,\n",
              " 3,\n",
              " 150,\n",
              " 259,\n",
              " 6,\n",
              " 2712,\n",
              " 14,\n",
              " 24]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqH8PqXjto0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "b09478c9-e7c8-4816-9e07-a9e080a08c7a"
      },
      "source": [
        "for i in sequences[0]:\n",
        "  print(f\"{i} :{tokenizer.index_word[i]}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "956 :call\n",
            "14 :me\n",
            "263 :ishmael\n",
            "51 :some\n",
            "261 :years\n",
            "408 :ago\n",
            "87 :never\n",
            "219 :mind\n",
            "129 :how\n",
            "111 :long\n",
            "954 :precisely\n",
            "260 :having\n",
            "50 :little\n",
            "43 :or\n",
            "38 :no\n",
            "315 :money\n",
            "7 :in\n",
            "23 :my\n",
            "546 :purse\n",
            "3 :and\n",
            "150 :nothing\n",
            "259 :particular\n",
            "6 :to\n",
            "2712 :interest\n",
            "14 :me\n",
            "24 :on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz8BLcuUtygt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer.word_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyFb4D9zuG1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size =len(tokenizer.word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ9VOP9vuPVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b11f7df-0726-405e-de2d-58d65596cc96"
      },
      "source": [
        "vocabulary_size"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr1oBWHvuQdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da1f8c50-3199-42a9-80c6-51dba2af6765"
      },
      "source": [
        "type(sequences)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFcIv_ZEuVa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFuak1TCuZEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences=np.array(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uMw61lPuegI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47a4d1f1-7dcb-4ab4-dfe8-70ec6f59ba8b"
      },
      "source": [
        "sequences.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11312, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqOSewsRuf1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d0cdcf5-fadf-4d48-fdc4-17d27bcec8c4"
      },
      "source": [
        "'''\n",
        "CREATE LSTM based model\n",
        "split data into features and labels\n",
        "fit the model\n",
        "'''"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCREATE LSTM based model\\nsplit data into features and labels\\nfit the model\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycJ26eUQu7dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp5hkHFKvDbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ccb8cb74-19de-462b-ffbf-515e4f58fb7e"
      },
      "source": [
        "sequences[:,:-1]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   14,  263, ...,    6, 2712,   14],\n",
              "       [  14,  263,   51, ..., 2712,   14,   24],\n",
              "       [ 263,   51,  261, ...,   14,   24,  957],\n",
              "       ...,\n",
              "       [ 952,   12,  166, ...,   11,  262,   53],\n",
              "       [  12,  166, 2711, ...,  262,   53,    2],\n",
              "       [ 166, 2711,    3, ...,   53,    2, 2717]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvmbmOhgvHNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1c2a9747-3e10-4881-afae-e0e81e579b84"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   14,  263, ..., 2712,   14,   24],\n",
              "       [  14,  263,   51, ...,   14,   24,  957],\n",
              "       [ 263,   51,  261, ...,   24,  957,    5],\n",
              "       ...,\n",
              "       [ 952,   12,  166, ...,  262,   53,    2],\n",
              "       [  12,  166, 2711, ...,   53,    2, 2717],\n",
              "       [ 166, 2711,    3, ...,    2, 2717,   26]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2fPCawtvIfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20d64e67-8008-4fc8-ba05-bc6488dc2809"
      },
      "source": [
        "sequences[:,-1]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  24,  957,    5, ...,    2, 2717,   26])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PyghYe8vQ-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X =sequences[:,:-1]\n",
        "y=sequences[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5kq_OiBvXdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y =to_categorical(y,num_classes=vocabulary_size+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPXjNhccvdJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len =X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkh4GrGnvge7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "749afec4-14b7-4a6b-82de-b8ac2db0d32e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11312, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOtuHGn9vhOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYwNpkkbv0oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocabulary_size,seq_len):\n",
        "  \n",
        "  model=Sequential()\n",
        "  model.add(Embedding(vocabulary_size,seq_len,input_length=seq_len))\n",
        "  model.add(LSTM(50,return_sequences=True))\n",
        "  model.add(LSTM(50))\n",
        "  model.add(Dense(50,activation='relu'))\n",
        "  \n",
        "  model.add(Dense(vocabulary_size,activation='softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGwavtLJwuUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "8cec340b-3e76-4e67-a0a9-fe4fd9ecf251"
      },
      "source": [
        "model=create_model(vocabulary_size+1,seq_len)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 18:31:23.027662 139943550044032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0618 18:31:23.074262 139943550044032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0618 18:31:23.084087 139943550044032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0618 18:31:23.533147 139943550044032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0618 18:31:23.556236 139943550044032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 25)            67950     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 25, 50)            15200     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2718)              138618    \n",
            "=================================================================\n",
            "Total params: 244,518\n",
            "Trainable params: 244,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Vi8AeFw1jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump,load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WszqE7SJxDdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1839
        },
        "outputId": "752c93d4-3b48-4392-e3fa-d5079a785fb0"
      },
      "source": [
        "model.fit(X,y,batch_size=128,epochs=50,verbose=1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 18:31:23.874579 139943550044032 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0618 18:31:25.166618 139943550044032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "11312/11312 [==============================] - 16s 1ms/step - loss: 6.9891 - acc: 0.0429\n",
            "Epoch 2/50\n",
            "11312/11312 [==============================] - 7s 605us/step - loss: 6.3755 - acc: 0.0529\n",
            "Epoch 3/50\n",
            "11312/11312 [==============================] - 7s 610us/step - loss: 6.3469 - acc: 0.0529\n",
            "Epoch 4/50\n",
            "11312/11312 [==============================] - 7s 604us/step - loss: 6.3367 - acc: 0.0529\n",
            "Epoch 5/50\n",
            "11312/11312 [==============================] - 7s 601us/step - loss: 6.3205 - acc: 0.0529\n",
            "Epoch 6/50\n",
            "11312/11312 [==============================] - 7s 600us/step - loss: 6.2262 - acc: 0.0529\n",
            "Epoch 7/50\n",
            "11312/11312 [==============================] - 7s 603us/step - loss: 6.1044 - acc: 0.0534\n",
            "Epoch 8/50\n",
            "11312/11312 [==============================] - 7s 600us/step - loss: 6.0010 - acc: 0.0543\n",
            "Epoch 9/50\n",
            "11312/11312 [==============================] - 7s 602us/step - loss: 5.9347 - acc: 0.0545\n",
            "Epoch 10/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 5.8811 - acc: 0.0568\n",
            "Epoch 11/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 5.8332 - acc: 0.0648\n",
            "Epoch 12/50\n",
            "11312/11312 [==============================] - 7s 597us/step - loss: 5.7850 - acc: 0.0664\n",
            "Epoch 13/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 5.7426 - acc: 0.0672\n",
            "Epoch 14/50\n",
            "11312/11312 [==============================] - 7s 603us/step - loss: 5.7040 - acc: 0.0675\n",
            "Epoch 15/50\n",
            "11312/11312 [==============================] - 7s 610us/step - loss: 5.6697 - acc: 0.0687\n",
            "Epoch 16/50\n",
            "11312/11312 [==============================] - 7s 597us/step - loss: 5.6364 - acc: 0.0690\n",
            "Epoch 17/50\n",
            "11312/11312 [==============================] - 7s 603us/step - loss: 5.6082 - acc: 0.0687\n",
            "Epoch 18/50\n",
            "11312/11312 [==============================] - 7s 600us/step - loss: 5.5814 - acc: 0.0721\n",
            "Epoch 19/50\n",
            "11312/11312 [==============================] - 7s 594us/step - loss: 5.5557 - acc: 0.0743\n",
            "Epoch 20/50\n",
            "11312/11312 [==============================] - 7s 599us/step - loss: 5.5343 - acc: 0.0758\n",
            "Epoch 21/50\n",
            "11312/11312 [==============================] - 7s 599us/step - loss: 5.5163 - acc: 0.0743\n",
            "Epoch 22/50\n",
            "11312/11312 [==============================] - 7s 599us/step - loss: 5.4937 - acc: 0.0752\n",
            "Epoch 23/50\n",
            "11312/11312 [==============================] - 7s 598us/step - loss: 5.4779 - acc: 0.0777\n",
            "Epoch 24/50\n",
            "11312/11312 [==============================] - 7s 595us/step - loss: 5.4570 - acc: 0.0792\n",
            "Epoch 25/50\n",
            "11312/11312 [==============================] - 7s 595us/step - loss: 5.4344 - acc: 0.0787\n",
            "Epoch 26/50\n",
            "11312/11312 [==============================] - 7s 607us/step - loss: 5.4145 - acc: 0.0783\n",
            "Epoch 27/50\n",
            "11312/11312 [==============================] - 7s 606us/step - loss: 5.3887 - acc: 0.0789\n",
            "Epoch 28/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 5.3626 - acc: 0.0830\n",
            "Epoch 29/50\n",
            "11312/11312 [==============================] - 7s 595us/step - loss: 5.3353 - acc: 0.0828\n",
            "Epoch 30/50\n",
            "11312/11312 [==============================] - 7s 598us/step - loss: 5.3079 - acc: 0.0842\n",
            "Epoch 31/50\n",
            "11312/11312 [==============================] - 7s 600us/step - loss: 5.2856 - acc: 0.0851\n",
            "Epoch 32/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 5.2605 - acc: 0.0855\n",
            "Epoch 33/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 5.2404 - acc: 0.0880\n",
            "Epoch 34/50\n",
            "11312/11312 [==============================] - 7s 599us/step - loss: 5.2187 - acc: 0.0863\n",
            "Epoch 35/50\n",
            "11312/11312 [==============================] - 7s 599us/step - loss: 5.1960 - acc: 0.0918\n",
            "Epoch 36/50\n",
            "11312/11312 [==============================] - 7s 595us/step - loss: 5.1777 - acc: 0.0901\n",
            "Epoch 37/50\n",
            "11312/11312 [==============================] - 7s 595us/step - loss: 5.1566 - acc: 0.0935\n",
            "Epoch 38/50\n",
            "11312/11312 [==============================] - 7s 603us/step - loss: 5.1373 - acc: 0.0917\n",
            "Epoch 39/50\n",
            "11312/11312 [==============================] - 7s 616us/step - loss: 5.1163 - acc: 0.0951\n",
            "Epoch 40/50\n",
            "11312/11312 [==============================] - 7s 604us/step - loss: 5.0993 - acc: 0.0980\n",
            "Epoch 41/50\n",
            "11312/11312 [==============================] - 7s 605us/step - loss: 5.0787 - acc: 0.0989\n",
            "Epoch 42/50\n",
            "11312/11312 [==============================] - 7s 607us/step - loss: 5.0580 - acc: 0.1029\n",
            "Epoch 43/50\n",
            "11312/11312 [==============================] - 7s 604us/step - loss: 5.0345 - acc: 0.1028\n",
            "Epoch 44/50\n",
            "11312/11312 [==============================] - 7s 627us/step - loss: 5.0145 - acc: 0.1061\n",
            "Epoch 45/50\n",
            "11312/11312 [==============================] - 7s 611us/step - loss: 4.9909 - acc: 0.1067\n",
            "Epoch 46/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 4.9692 - acc: 0.1096\n",
            "Epoch 47/50\n",
            "11312/11312 [==============================] - 7s 591us/step - loss: 4.9469 - acc: 0.1115\n",
            "Epoch 48/50\n",
            "11312/11312 [==============================] - 7s 596us/step - loss: 4.9241 - acc: 0.1115\n",
            "Epoch 49/50\n",
            "11312/11312 [==============================] - 7s 592us/step - loss: 4.9023 - acc: 0.1129\n",
            "Epoch 50/50\n",
            "11312/11312 [==============================] - 7s 603us/step - loss: 4.8818 - acc: 0.1168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f46441fcb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoAXNqMPxYHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_mobydick_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRQ5JkcpxxIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(tokenizer,open('my_simpletokenizer','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LufQ0b_bx6bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate new text based off of a seed input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDH0-l6Ky3bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeRFXBxeyJS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model,tokenizer,seq_len,seed_text,num_gen_words):\n",
        "  output_text=[]\n",
        "  \n",
        "  input_text=seed_text\n",
        "  \n",
        "  for i in range(num_gen_words):\n",
        "    encoded_text=tokenizer.texts_to_sequences([input_text])[0]\n",
        "    \n",
        "    pad_encoded =pad_sequences([encoded_text], maxlen=seq_len,\n",
        "                              truncating='pre')\n",
        "    \n",
        "    pred_word_ind=model.predict_classes(pad_encoded,verbose=0)[0]\n",
        "    \n",
        "    pred_word=tokenizer.index_word[pred_word_ind]\n",
        "    \n",
        "    input_text+= ' '+pred_word\n",
        "    \n",
        "    output_text.append(pred_word)\n",
        "  \n",
        "  return ' '.join(output_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx7bohlh0_On",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "77088a53-f9e9-4d23-ab18-4bae749d4b2a"
      },
      "source": [
        "text_sqequences[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['call',\n",
              " 'me',\n",
              " 'ishmael',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no',\n",
              " 'money',\n",
              " 'in',\n",
              " 'my',\n",
              " 'purse',\n",
              " 'and',\n",
              " 'nothing',\n",
              " 'particular',\n",
              " 'to',\n",
              " 'interest',\n",
              " 'me',\n",
              " 'on']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6GLgIvH1CpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(101)\n",
        "random_pick=random.randint(0,len(text_sqequences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9AMKUDG1LPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed_text=text_sqequences[random_pick]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjxK7O521Oy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "b48bc0a7-8e5d-4e03-9667-ff77382ff4ee"
      },
      "source": [
        "random_seed_text"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thought',\n",
              " 'i',\n",
              " 'to',\n",
              " 'myself',\n",
              " 'the',\n",
              " 'man',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'human',\n",
              " 'being',\n",
              " 'just',\n",
              " 'as',\n",
              " 'i',\n",
              " 'am',\n",
              " 'he',\n",
              " 'has',\n",
              " 'just',\n",
              " 'as',\n",
              " 'much',\n",
              " 'reason',\n",
              " 'to',\n",
              " 'fear',\n",
              " 'me',\n",
              " 'as',\n",
              " 'i',\n",
              " 'have']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDr8DG-C1P3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text=' '.join(random_seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahxfvoox1UGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7b36895-f59b-4485-9301-25b368260512"
      },
      "source": [
        "seed_text"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"thought i to myself the man 's a human being just as i am he has just as much reason to fear me as i have\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_XpQWUA1VKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e408d797-526d-45af-e9e9-38caf925b9be"
      },
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text,num_gen_words=25)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'not be be be be be be be be be be be be be be be be be be be be be be be be'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOMHyBDU1nbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}