{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment-Analysis-Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetansolanke14/NaturalLanguageProcessing/blob/master/SemanticAndSentiment/Sentiment_Analysis_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRLXxuz3VED0",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis Project\n",
        "For this project, we'll perform the same type of NLTK VADER sentiment analysis, this time on our movie reviews dataset.\n",
        "\n",
        "The 2,000 record IMDb movie review database is accessible through NLTK directly with\n",
        "<pre>from nltk.corpus import movie_reviews</pre>\n",
        "\n",
        "However, since we already have it in a tab-delimited file we'll use that instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbykvaPTVED1",
        "colab_type": "text"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0taU8t3Vi7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wETniCrdVklM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de685c94-a0aa-4949-f16b-f534261b819d"
      },
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vnMU3IbVED2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "134124ac-71b0-4847-dec8-609d3e3125d6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('moviereviews.tsv', sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>how do films like mouse hunt get into theatres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>some talented actresses are blessed with a dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>this has been an extraordinary year for austra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>according to hollywood movies made in last few...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>my first press screening of 1998 and already i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                             review\n",
              "0   neg  how do films like mouse hunt get into theatres...\n",
              "1   neg  some talented actresses are blessed with a dem...\n",
              "2   pos  this has been an extraordinary year for austra...\n",
              "3   pos  according to hollywood movies made in last few...\n",
              "4   neg  my first press screening of 1998 and already i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6tEBQcHVED7",
        "colab_type": "text"
      },
      "source": [
        "## Remove Blank Records (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLrM3LdPVED8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# REMOVE NaN VALUES AND EMPTY STRINGS:\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "blanks = []  # start with an empty list\n",
        "\n",
        "for i,lb,rv in df.itertuples():  # iterate over the DataFrame\n",
        "    if type(rv)==str:            # avoid NaN values\n",
        "        if rv.isspace():         # test 'review' for whitespace\n",
        "            blanks.append(i)     # add matching index numbers to the list\n",
        "\n",
        "df.drop(blanks, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BRl6qDeVED-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d5d8d9c3-75c9-4f97-de05-dedd57e30fad"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    969\n",
              "neg    969\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFt_ZRFfVEEC",
        "colab_type": "text"
      },
      "source": [
        "## Import `SentimentIntensityAnalyzer` and create an sid object\n",
        "This assumes that the VADER lexicon has been downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIjae9EWVEED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDF7rgXKVEEG",
        "colab_type": "text"
      },
      "source": [
        "## Use sid to append a `comp_score` to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXl9vREKVEEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3452b555-b259-4c42-9f69-9dd95ef4124b"
      },
      "source": [
        "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
        "\n",
        "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "\n",
        "df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound</th>\n",
              "      <th>comp_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>how do films like mouse hunt get into theatres...</td>\n",
              "      <td>{'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...</td>\n",
              "      <td>-0.9125</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>some talented actresses are blessed with a dem...</td>\n",
              "      <td>{'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...</td>\n",
              "      <td>-0.8618</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>this has been an extraordinary year for austra...</td>\n",
              "      <td>{'neg': 0.067, 'neu': 0.783, 'pos': 0.15, 'com...</td>\n",
              "      <td>0.9953</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>according to hollywood movies made in last few...</td>\n",
              "      <td>{'neg': 0.069, 'neu': 0.786, 'pos': 0.145, 'co...</td>\n",
              "      <td>0.9972</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>my first press screening of 1998 and already i...</td>\n",
              "      <td>{'neg': 0.09, 'neu': 0.822, 'pos': 0.088, 'com...</td>\n",
              "      <td>-0.7264</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                             review  ... compound  comp_score\n",
              "0   neg  how do films like mouse hunt get into theatres...  ...  -0.9125         neg\n",
              "1   neg  some talented actresses are blessed with a dem...  ...  -0.8618         neg\n",
              "2   pos  this has been an extraordinary year for austra...  ...   0.9953         pos\n",
              "3   pos  according to hollywood movies made in last few...  ...   0.9972         pos\n",
              "4   neg  my first press screening of 1998 and already i...  ...  -0.7264         neg\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUBAdQd6VEEK",
        "colab_type": "text"
      },
      "source": [
        "## Perform a comparison analysis between the original `label` and `comp_score`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9nvfDGQVEEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjsstoyJVEEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff7ad9e0-326a-470a-971c-9cd9f750daf0"
      },
      "source": [
        "accuracy_score(df['label'],df['comp_score'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6367389060887513"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ27up65VEES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "91653af3-1dbd-48ce-f9f7-0998f60c4fce"
      },
      "source": [
        "print(classification_report(df['label'],df['comp_score']))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.72      0.44      0.55       969\n",
            "         pos       0.60      0.83      0.70       969\n",
            "\n",
            "    accuracy                           0.64      1938\n",
            "   macro avg       0.66      0.64      0.62      1938\n",
            "weighted avg       0.66      0.64      0.62      1938\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fFKPHqVEEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7780cf4c-0667-40fb-a409-3791e0b91259"
      },
      "source": [
        "print(confusion_matrix(df['label'],df['comp_score']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[427 542]\n",
            " [162 807]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF32WS6gVEEY",
        "colab_type": "text"
      },
      "source": [
        "So, it looks like VADER couldn't judge the movie reviews very accurately. This demonstrates one of the biggest challenges in sentiment analysis - understanding human semantics. Many of the reviews had positive things to say about a movie, reserving final judgement to the last sentence.\n",
        "## Great Job!"
      ]
    }
  ]
}